<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Project Title</title>
  <link rel="stylesheet" href="css/style.css" />
  <script src="script.js" defer></script>
</head>
<body>
  <div class="wrapper">
    <h1 class="title">UniVST: A Unified Framework for Training-free Localized Video Style Transfer</h1>

    <div class="authors">
      <a href="#">Quanjian Song<sup>1</sup></a>,
      <a href="#">Mingbao Lin<sup>2</sup></a>,
      <a href="#">Wengyi Zhan<sup>2</sup></a>,
      <a href="#">Shuicheng Yan<sup>2</sup></a>,
      <a href="#">Liujuan Cao<sup>3</sup></a>,
      <a href="#">Rongrong Ji<sup>2</sup></a>
    </div>

    <div class="affiliations">
      <span><sup>1</sup>Key Laboratory of Multimedia Trusted Perception and Efficient Computing, <br> Ministry of Education of China, Xiamen University, China.</span>,
      <span><sup>2</sup>Kunlun Skywork AI</span>
    </div>

    <div class="buttons">
      <a class="btn" href="#">📝 arXiv</a>
      <a class="btn" href="#">📄 Supplementary</a>
      <a class="btn" href="#">💻 Code</a>
      <a class="btn" href="#">🤖 Online Demo</a>
    </div>

    <p class="tldr"><strong>TL;DR:</strong> We propose StyleCrafter, a generic method that enhances pre-trained T2V models with style control, supporting Style-Guided Text-to-Image Generation and Style-Guided Text-to-Video Generation.</p>
  </div>
</body>
</html>
